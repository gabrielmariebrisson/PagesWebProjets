{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e157927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e29b822a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/holehe-1.61-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\r\n",
      "\u001b[0mRequirement already satisfied: pydub in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.25.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c0212c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define root directory\n",
    "root_dir = '/tmp/GTZAN'\n",
    "source_dir=os.getcwd()+'/../../data/Data/genres_original'\n",
    "\n",
    "\n",
    "if os.path.exists(root_dir):\n",
    "  shutil.rmtree(root_dir)\n",
    "\n",
    "def create_train_val_dirs(tmp_path,SOURCE_DIR):\n",
    "    \"\"\"\n",
    "    Creates directories for the train and test sets\n",
    "\n",
    "    Args:\n",
    "    tmp_path (string) - the base directory path to create subdirectories from\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE\n",
    "\n",
    "    # HINT:\n",
    "    # Use os.makedirs to create your directories with intermediate subdirectories\n",
    "    # Don't hardcode the paths. Use os.path.join to append the new directories to the tmp_path parameter\n",
    "\n",
    "\n",
    "    tmp_path_training = os.path.join(tmp_path, 'training')\n",
    "    tmp_path_validation = os.path.join(tmp_path, 'validation')\n",
    "    tmp_path_test = os.path.join(tmp_path, 'test')\n",
    "    \n",
    "    os.makedirs(tmp_path_training)\n",
    "    os.makedirs(tmp_path_validation)\n",
    "    os.makedirs(tmp_path_test)\n",
    "    \"\"\"\n",
    "    for repertory in os.listdir(SOURCE_DIR):\n",
    "        \n",
    "        repertory_path = os.path.join(SOURCE_DIR, repertory)\n",
    "        if not os.path.isdir(repertory_path) or repertory == \".DS_Store\":\n",
    "            continue\n",
    "            \n",
    "        tmp_path_training_repertory = os.path.join(tmp_path_training, repertory)\n",
    "        tmp_path_validation_repertory = os.path.join(tmp_path_validation, repertory)\n",
    "        tmp_path_test_repertory = os.path.join(tmp_path_test, repertory)\n",
    "\n",
    "        os.makedirs(tmp_path_training_repertory)\n",
    "        os.makedirs(tmp_path_validation_repertory)\n",
    "        os.makedirs(tmp_path_test_repertory)\"\"\"\n",
    "        \n",
    "try:\n",
    "    create_train_val_dirs(tmp_path=root_dir,SOURCE_DIR=source_dir )\n",
    "except FileExistsError:\n",
    "    print(\"You should not be seeing this since the upper directory is removed beforehand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "011efcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/GTZAN/test\n",
      "/tmp/GTZAN/training\n",
      "/tmp/GTZAN/validation\n"
     ]
    }
   ],
   "source": [
    "# Test your create_train_val_dirs function\n",
    "\n",
    "for rootdir, dirs, files in os.walk(root_dir):\n",
    "    for subdir in dirs:\n",
    "        print(os.path.join(rootdir, subdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36aa7d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root=os.getcwd()+'/../../data/Data/genres_original'\n",
    "\n",
    "def copy_data_from_source_to(tab_files, SOURCE_DIR, PATH_DIR):\n",
    "    for file in tab_files:\n",
    "        source_path = os.path.join(SOURCE_DIR, file)\n",
    "        destination_path = os.path.join(PATH_DIR, file)\n",
    "\n",
    "        if os.path.getsize(source_path) > 0 and source_path.endswith(\".wav\"):\n",
    "            shutil.copy(source_path, destination_path)\n",
    "        else:\n",
    "            print(f\"{file} is zero length, so ignoring.\")\n",
    "    print(tab_files[0])\n",
    "    #pixel_count = get_image_pixel_count(tab_files[0])\n",
    "    #print( tab_files[0].dtype)\n",
    "\n",
    "# SPLIT = 80/10/10\n",
    "def split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, TEST_DIR):\n",
    "    all_files = os.listdir(SOURCE_DIR)\n",
    "    random.shuffle(all_files)\n",
    "\n",
    "    split_one = int(len(all_files) * 0.8)\n",
    "    split_two = int(len(all_files) * 0.9)\n",
    "    \n",
    "    training_files = all_files[:split_one]\n",
    "    validation_files = all_files[split_one:split_two]\n",
    "    test_files = all_files[split_two:]\n",
    "\n",
    "    copy_data_from_source_to(training_files, SOURCE_DIR, TRAINING_DIR)\n",
    "    copy_data_from_source_to(validation_files, SOURCE_DIR, VALIDATION_DIR)\n",
    "    copy_data_from_source_to(test_files, SOURCE_DIR, TEST_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5edf2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/GTZAN/test\n",
      "/tmp/GTZAN/training\n",
      "/tmp/GTZAN/validation\n",
      "pop.00042.wav\n",
      "pop.00038.wav\n",
      "pop.00010.wav\n",
      "Original directory has 100 images of  pop \n",
      "\n",
      "There are 80 images of  pop  for training\n",
      "There are 10 images of  pop  for validation\n",
      "There are 10 images of  pop  for testing\n",
      "metal.00063.wav\n",
      "metal.00035.wav\n",
      "metal.00058.wav\n",
      "Original directory has 100 images of  metal \n",
      "\n",
      "There are 160 images of  metal  for training\n",
      "There are 20 images of  metal  for validation\n",
      "There are 20 images of  metal  for testing\n",
      "disco.00098.wav\n",
      "disco.00065.wav\n",
      "disco.00023.wav\n",
      "Original directory has 100 images of  disco \n",
      "\n",
      "There are 240 images of  disco  for training\n",
      "There are 30 images of  disco  for validation\n",
      "There are 30 images of  disco  for testing\n",
      "blues.00067.wav\n",
      "blues.00005.wav\n",
      "blues.00054.wav\n",
      "Original directory has 100 images of  blues \n",
      "\n",
      "There are 320 images of  blues  for training\n",
      "There are 40 images of  blues  for validation\n",
      "There are 40 images of  blues  for testing\n",
      "reggae.00029.wav\n",
      "reggae.00060.wav\n",
      "reggae.00046.wav\n",
      "Original directory has 100 images of  reggae \n",
      "\n",
      "There are 400 images of  reggae  for training\n",
      "There are 50 images of  reggae  for validation\n",
      "There are 50 images of  reggae  for testing\n",
      "classical.00097.wav\n",
      "classical.00055.wav\n",
      "classical.00091.wav\n",
      "Original directory has 100 images of  classical \n",
      "\n",
      "There are 480 images of  classical  for training\n",
      "There are 60 images of  classical  for validation\n",
      "There are 60 images of  classical  for testing\n",
      "rock.00012.wav\n",
      "rock.00097.wav\n",
      "rock.00041.wav\n",
      "Original directory has 100 images of  rock \n",
      "\n",
      "There are 560 images of  rock  for training\n",
      "There are 70 images of  rock  for validation\n",
      "There are 70 images of  rock  for testing\n",
      "hiphop.00014.wav\n",
      "hiphop.00071.wav\n",
      "hiphop.00043.wav\n",
      "Original directory has 100 images of  hiphop \n",
      "\n",
      "There are 640 images of  hiphop  for training\n",
      "There are 80 images of  hiphop  for validation\n",
      "There are 80 images of  hiphop  for testing\n",
      "country.00093.wav\n",
      "country.00007.wav\n",
      "country.00071.wav\n",
      "Original directory has 100 images of  country \n",
      "\n",
      "There are 720 images of  country  for training\n",
      "There are 90 images of  country  for validation\n",
      "There are 90 images of  country  for testing\n",
      "jazz.00053.wav\n",
      "jazz.00079.wav\n",
      ".DS_Store is zero length, so ignoring.\n",
      "jazz.00050.wav\n",
      "Original directory has 100 images of  jazz \n",
      "\n",
      "There are 800 images of  jazz  for training\n",
      "There are 100 images of  jazz  for validation\n",
      "There are 99 images of  jazz  for testing\n"
     ]
    }
   ],
   "source": [
    "TEST_DIR= os.path.join( root_dir,os.listdir(root_dir)[0]) \n",
    "TRAINING_DIR= os.path.join( root_dir,os.listdir(root_dir)[1])\n",
    "VALIDATION_DIR= os.path.join( root_dir,os.listdir(root_dir)[2])\n",
    "\n",
    "print (TEST_DIR)\n",
    "print (TRAINING_DIR)\n",
    "print (VALIDATION_DIR)\n",
    "\n",
    "for rootdir, dirs, files in os.walk(source_dir):\n",
    "    for subdir in dirs:\n",
    "        SUB_ROOT_DIR=os.path.join(rootdir, subdir)\n",
    "        \n",
    "        split_data(SOURCE_DIR=SUB_ROOT_DIR, TRAINING_DIR=TRAINING_DIR, VALIDATION_DIR=VALIDATION_DIR, TEST_DIR=TEST_DIR)\n",
    "        \n",
    "        print(f\"Original directory has {len(os.listdir(SUB_ROOT_DIR))} images of \",subdir,\"\\n\")\n",
    "        \n",
    "        print(f\"There are {len(os.listdir(TRAINING_DIR))} images of \",subdir,\" for training\")\n",
    "        print(f\"There are {len(os.listdir(VALIDATION_DIR))} images of \",subdir,\" for validation\")\n",
    "        print(f\"There are {len(os.listdir(TEST_DIR))} images of \",subdir,\" for testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14371a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "import librosa\n",
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "label_mapping = {'blues': 0, 'classical': 1, 'country': 2, 'disco': 3, 'hiphop': 4,'jazz': 5,'metal': 6,'pop': 7,'reggae': 8, 'rock': 9 }\n",
    "\n",
    "\n",
    "\"\"\"def convertSongToMatrice(audio_path, size=599):\n",
    "    y, sr = librosa.load(audio_path)\n",
    "    win_length=sr/10\n",
    "    print(sr)\n",
    "\n",
    "    D = np.abs(librosa.stft(y,win_length=win_length, hop_length=win_lenght/2))# 50 miliseconde pour le  hop size\n",
    "    spectrogram = librosa.feature.melspectrogram(S=D, sr=sr)\n",
    "    spectrogram = librosa.util.fix_length(spectrogram,size= size)\n",
    "    print(spectrogram.shape)\n",
    "    return spectrogram\n",
    "\"\"\"\n",
    "def convertSongToMatrice(audio_path, size=599):\n",
    "    y, sr = librosa.load(audio_path)\n",
    "    n_fft= (sr/10) /2 +3\n",
    "    #print(n_fft)\n",
    "    D = np.abs(librosa.stft(y ,hop_length= int(n_fft)))\n",
    "    spectrogram = librosa.feature.melspectrogram(S=D, sr=sr)\n",
    "    #print(spectrogram.shape)\n",
    "    spectrogram = librosa.util.fix_length(spectrogram,size= size)\n",
    "    \n",
    "    return spectrogram\n",
    "\n",
    "def string_to_label(string, mapping):\n",
    "    return mapping[string]\n",
    "\n",
    "\n",
    "def createDataset(files):\n",
    "    list_Matrice = []\n",
    "    list_label = []\n",
    "\n",
    "    for root, dirs, files in os.walk(files):\n",
    "        for SongName in files:\n",
    "            audio_path = os.path.join(root, SongName)\n",
    "\n",
    "            spectrogram = convertSongToMatrice(audio_path)\n",
    "            spectrogram = torch.tensor(spectrogram)\n",
    "            # Ajouter la dimension du canal\n",
    "            spectrogram = spectrogram.unsqueeze(0)\n",
    "            \n",
    "            label = string_to_label(SongName.split('.')[0],label_mapping)\n",
    "\n",
    "            list_Matrice.append(spectrogram)\n",
    "            list_label.append(label)\n",
    "\n",
    "    tensor_x = torch.stack(list_Matrice) \n",
    "    tensor_y = torch.LongTensor(list_label)\n",
    "    print (\"tensor_x\",tensor_x.shape)\n",
    "    print (\"tensor_y\",tensor_y.shape)\n",
    "\n",
    "    dataset = TensorDataset(tensor_x, tensor_y)\n",
    "    return dataset\n",
    "\n",
    "def train_val_generators(TRAINING_DIR, VALIDATION_DIR, TEST_DIR, batch_size=32):\n",
    "    train_dataset = createDataset(TRAINING_DIR)\n",
    "    validation_dataset = createDataset(VALIDATION_DIR)\n",
    "    test_dataset = createDataset(TEST_DIR)\n",
    "\n",
    "    train_generator = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    validation_generator = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_generator = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_generator, validation_generator, test_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ba449ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_x torch.Size([800, 1, 128, 599])\n",
      "tensor_y torch.Size([800])\n",
      "tensor_x torch.Size([100, 1, 128, 599])\n",
      "tensor_y torch.Size([100])\n",
      "tensor_x torch.Size([99, 1, 128, 599])\n",
      "tensor_y torch.Size([99])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_generator, validation_generator, test_generator = train_val_generators(TRAINING_DIR, VALIDATION_DIR, TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "08892065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(Module):\n",
    "    def __init__(self):\n",
    "        # call the parent constructor\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional layer convolution d'une matrice de taille total 128x599 en convolutionnant des layer de taille 128x4 avec un pas de en 0x1 \n",
    "        # PADDING 4 DIMENSION\n",
    "        self.norm1 = nn.BatchNorm2d(1) \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=256, kernel_size=(128,4), padding=(0,1))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(1,4))\n",
    "        \n",
    "        # Convolutional layer 2\n",
    "        self.norm2 = nn.BatchNorm2d(1) \n",
    "        self.conv2 = nn.Conv2d(in_channels=1, out_channels=256, kernel_size= (256,4)) \n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(1,2))\n",
    "        \n",
    "        self.norm3 = nn.BatchNorm2d(1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=1, out_channels=512, kernel_size=(256,4) )\n",
    "        \n",
    "        self.norm4 = nn.BatchNorm2d(1) \n",
    "        self.conv4 = nn.Conv2d(in_channels=1, out_channels=512, kernel_size=(512,4) )\n",
    "\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.normfc2 = nn.BatchNorm1d(1536) \n",
    "        self.fc2 = nn.Linear(1536, 2048)\n",
    "        self.normfc3 = nn.BatchNorm1d(2048) \n",
    "        self.fc3 = nn.Linear(2048, 2048)\n",
    "        self.normfc4 = nn.BatchNorm1d(2048) \n",
    "        self.fc4 = nn.Linear(2048, 10)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\" input layer :\", x.shape)\n",
    "        \n",
    "        #print (\" first  layer\")\n",
    "        x = self.norm1(x)\n",
    "        #print(\" norm1 :\", x.shape)\n",
    "        x = self.conv1(x)\n",
    "        #print(\" conv1 :\", x.shape)\n",
    "        x = self.relu(x)\n",
    "        #print(\" relu :\", x.shape)\n",
    "        x = self.pool1(x)\n",
    "        #print(\" pool1 :\", x.shape)\n",
    "        x = torch.permute(x,(0,2,1,3))\n",
    "        #print(\" permute 1 :\", x.shape)\n",
    "        \n",
    "        #print (\" second  layer\")\n",
    "        x = self.norm2(x)\n",
    "        #print(\" norm2 :\", x.shape)\n",
    "        x = self.conv2(x)\n",
    "        #print(\" conv2 :\", x.shape)\n",
    "        x = self.relu(x)\n",
    "        #print(\" relu :\", x.shape)\n",
    "        x = self.pool2(x)\n",
    "        #print(\" pool2 :\", x.shape)\n",
    "        x = torch.permute(x,(0,2,1,3))\n",
    "        #print(\" permute 2 :\", x.shape)\n",
    "        \n",
    "        \n",
    "        #print (\" third  layer\")\n",
    "        x = self.norm3(x)\n",
    "        #print(\" norm3 :\", x.shape)\n",
    "        x = self.conv3(x)\n",
    "        #print(\" conv3 :\", x.shape)\n",
    "        x = self.relu(x)\n",
    "        #print(\" relu :\", x.shape)\n",
    "        x = self.pool2(x)\n",
    "        #print(\" pool2 :\", x.shape)\n",
    "        x = torch.permute(x,(0,2,1,3))\n",
    "        #print(\" permute 3 :\", x.shape)\n",
    "        \n",
    "        #print (\" four bis  layer\")\n",
    "        x = self.norm4(x)\n",
    "        #print(\" norm4 :\", x.shape)\n",
    "        x = self.conv4(x)\n",
    "        #print(\" conv4 :\", x.shape)\n",
    "        x = self.relu(x)\n",
    "        #print(\" relu :\", x.shape)\n",
    "        x = torch.permute(x,(0,2,1,3))\n",
    "        #print(\" permute 4 :\", x.shape)\n",
    "        \n",
    "        #print (\" five sub layer \")\n",
    "        mean_values = torch.mean(x, dim=3, keepdim=True)\n",
    "        #print(mean_values.shape)\n",
    "        max_values, _ = torch.max(x, dim=3, keepdim=True)\n",
    "        #print(max_values.shape)\n",
    "        l2_norm = torch.linalg.norm(x, dim=3, ord= 2, keepdim=True)\n",
    "        #print(l2_norm.shape)\n",
    "        \n",
    "        #print (\" five  layer \")\n",
    "        x = torch.cat([max_values, mean_values, l2_norm], dim=1)  # Concat√©ner sur la dimension 1\n",
    "        #print (\" Global Temporal pooling\", x.shape)\n",
    "        \n",
    "        \n",
    "        x = x.view(-1, 1536)\n",
    "        #print (\" six  layer \")\n",
    "        x = self.normfc2(x)\n",
    "        #print(\" normfc2 :\", x.shape)\n",
    "        x = self.fc2(x)\n",
    "        #print (\" fc2 \", x.shape)\n",
    "        x = F.relu(x)\n",
    "        #print (\" relu \", x.shape)\n",
    "        \n",
    "        #print (\" six  layer \")\n",
    "        x = self.normfc3(x)\n",
    "        #print(\" normfc3 :\", x.shape)\n",
    "        x = self.fc3(x)\n",
    "        #print (\" fc3 \", x.shape)\n",
    "        x = F.relu(x)\n",
    "        #print (\" relu \", x.shape)\n",
    "        \n",
    "        #print (\" six  layer \")\n",
    "        x = self.normfc4(x)\n",
    "        #print(\" normfc4 :\", x.shape)\n",
    "        x = self.fc4(x)\n",
    "        #print (\" fc4 \", x.shape)\n",
    "        #x = F.softmax(x, dim=1)\n",
    "        #print (\" output layer \", x.shape)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eaf3bc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model, criterion, optimizer, dataset):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(dataset):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        #print(\"outputs\",outputs)\n",
    "        #print(\"labels\",labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        #print(\"loss\",loss)\n",
    "        #print()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    average_loss = running_loss / len(dataset)\n",
    "    return accuracy, average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2c4077f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ValidatModel(model, criterion, optimizer, dataset):\n",
    "    val_running_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    for data in dataset:\n",
    "        inputs, labels = data\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_running_loss += loss.item()\n",
    "        \n",
    "        _, val_predicted = torch.max(outputs.data, 1)\n",
    "        val_total += labels.size(0)\n",
    "        val_correct += (val_predicted == labels).sum().item()\n",
    "        \n",
    "    val_accuracy = val_correct / val_total\n",
    "    val_average_loss = val_running_loss / len(dataset)\n",
    "    \n",
    "    return val_accuracy,val_average_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36ddd9a",
   "metadata": {},
   "source": [
    "Pour afficher le tensorboard il faut excuter 'tensorboard --logdir=runs' dans le repertoire ou il y a le fichier runs\n",
    "Puis aller sur l'url : http://localhost:6006/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f08ef48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Accuracy: 0.1075 - Average Loss: 2.4661 - Learning Rate: 1.2589254117941673e-05\n",
      "Epoch 1 - Accuracy: 0.2825 - Average Loss: 2.0179 - Learning Rate: 1.5848931924611138e-05\n",
      "Epoch 2 - Accuracy: 0.4200 - Average Loss: 1.7534 - Learning Rate: 1.9952623149688796e-05\n",
      "Epoch 3 - Accuracy: 0.4813 - Average Loss: 1.5889 - Learning Rate: 2.5118864315095805e-05\n",
      "Epoch 4 - Accuracy: 0.5537 - Average Loss: 1.4371 - Learning Rate: 3.1622776601683795e-05\n",
      "Epoch 5 - Accuracy: 0.6288 - Average Loss: 1.2750 - Learning Rate: 3.981071705534973e-05\n",
      "Epoch 6 - Accuracy: 0.6913 - Average Loss: 1.1428 - Learning Rate: 5.0118723362727224e-05\n",
      "Epoch 7 - Accuracy: 0.7325 - Average Loss: 1.0105 - Learning Rate: 6.309573444801933e-05\n",
      "Epoch 8 - Accuracy: 0.7775 - Average Loss: 0.9047 - Learning Rate: 7.943282347242817e-05\n",
      "Epoch 9 - Accuracy: 0.8187 - Average Loss: 0.7818 - Learning Rate: 0.0001\n",
      "Epoch 10 - Accuracy: 0.8337 - Average Loss: 0.6988 - Learning Rate: 0.00012589254117941674\n",
      "Epoch 11 - Accuracy: 0.8488 - Average Loss: 0.6302 - Learning Rate: 0.00015848931924611134\n",
      "Epoch 12 - Accuracy: 0.9050 - Average Loss: 0.5171 - Learning Rate: 0.00019952623149688798\n",
      "Epoch 13 - Accuracy: 0.9375 - Average Loss: 0.3783 - Learning Rate: 0.00025118864315095795\n",
      "Epoch 14 - Accuracy: 0.9600 - Average Loss: 0.2993 - Learning Rate: 0.00031622776601683794\n",
      "Epoch 15 - Accuracy: 0.9738 - Average Loss: 0.2355 - Learning Rate: 0.00039810717055349735\n",
      "Epoch 16 - Accuracy: 0.9550 - Average Loss: 0.2599 - Learning Rate: 0.0005011872336272723\n",
      "Epoch 17 - Accuracy: 0.9700 - Average Loss: 0.1810 - Learning Rate: 0.0006309573444801933\n",
      "Epoch 18 - Accuracy: 0.9725 - Average Loss: 0.1893 - Learning Rate: 0.0007943282347242814\n",
      "Epoch 19 - Accuracy: 0.9550 - Average Loss: 0.1925 - Learning Rate: 0.001\n",
      "Epoch 20 - Accuracy: 0.9613 - Average Loss: 0.1677 - Learning Rate: 0.0012589254117941677\n",
      "Epoch 21 - Accuracy: 0.9375 - Average Loss: 0.2382 - Learning Rate: 0.0015848931924611143\n",
      "Epoch 22 - Accuracy: 0.8575 - Average Loss: 0.4747 - Learning Rate: 0.001995262314968879\n",
      "Epoch 23 - Accuracy: 0.7775 - Average Loss: 0.6782 - Learning Rate: 0.00251188643150958\n",
      "Epoch 24 - Accuracy: 0.7013 - Average Loss: 0.8672 - Learning Rate: 0.00316227766016838\n",
      "Epoch 25 - Accuracy: 0.6425 - Average Loss: 1.1082 - Learning Rate: 0.003981071705534973\n",
      "Epoch 26 - Accuracy: 0.6062 - Average Loss: 1.3785 - Learning Rate: 0.005011872336272725\n",
      "Epoch 27 - Accuracy: 0.5775 - Average Loss: 1.4140 - Learning Rate: 0.00630957344480193\n",
      "Epoch 28 - Accuracy: 0.5988 - Average Loss: 1.3598 - Learning Rate: 0.007943282347242814\n",
      "Epoch 29 - Accuracy: 0.5800 - Average Loss: 1.5097 - Learning Rate: 0.01\n",
      "Epoch 30 - Accuracy: 0.6150 - Average Loss: 1.6420 - Learning Rate: 0.012589254117941677\n",
      "Epoch 31 - Accuracy: 0.5200 - Average Loss: 1.9379 - Learning Rate: 0.01584893192461114\n",
      "Epoch 32 - Accuracy: 0.4950 - Average Loss: 2.6780 - Learning Rate: 0.019952623149688792\n",
      "Epoch 33 - Accuracy: 0.3650 - Average Loss: 3.9424 - Learning Rate: 0.0251188643150958\n",
      "Epoch 34 - Accuracy: 0.4250 - Average Loss: 4.2941 - Learning Rate: 0.0316227766016838\n",
      "Epoch 35 - Accuracy: 0.3325 - Average Loss: 7.6821 - Learning Rate: 0.039810717055349734\n",
      "Epoch 36 - Accuracy: 0.3375 - Average Loss: 6.7175 - Learning Rate: 0.050118723362727255\n",
      "Epoch 37 - Accuracy: 0.2125 - Average Loss: 13.0363 - Learning Rate: 0.0630957344480193\n",
      "Epoch 38 - Accuracy: 0.2500 - Average Loss: 11.9013 - Learning Rate: 0.07943282347242814\n",
      "Epoch 39 - Accuracy: 0.2338 - Average Loss: 9.4635 - Learning Rate: 0.1\n",
      "Epoch 40 - Accuracy: 0.3063 - Average Loss: 8.3109 - Learning Rate: 0.12589254117941664\n",
      "Epoch 41 - Accuracy: 0.2137 - Average Loss: 6.9606 - Learning Rate: 0.15848931924611143\n",
      "Epoch 42 - Accuracy: 0.2300 - Average Loss: 3.0594 - Learning Rate: 0.1995262314968879\n",
      "Epoch 43 - Accuracy: 0.2288 - Average Loss: 2.4462 - Learning Rate: 0.25118864315095824\n",
      "Epoch 44 - Accuracy: 0.2762 - Average Loss: 2.0445 - Learning Rate: 0.31622776601683794\n",
      "Epoch 45 - Accuracy: 0.2313 - Average Loss: 2.0616 - Learning Rate: 0.3981071705534969\n",
      "Epoch 46 - Accuracy: 0.2437 - Average Loss: 2.0007 - Learning Rate: 0.5011872336272726\n",
      "Epoch 47 - Accuracy: 0.2562 - Average Loss: 2.1115 - Learning Rate: 0.630957344480193\n",
      "Epoch 48 - Accuracy: 0.2263 - Average Loss: 2.4347 - Learning Rate: 0.7943282347242822\n",
      "Epoch 49 - Accuracy: 0.2575 - Average Loss: 2.6941 - Learning Rate: 1.0\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5, momentum=0.9)\n",
    "lambda1 = lambda epoch: 10**(epoch/10)\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=[lambda1])\n",
    "\n",
    "tabLearningRate=[]\n",
    "tabLoss=[]\n",
    "\n",
    "epoch=0\n",
    "while(optimizer.param_groups[0][\"lr\"]<1 and optimizer.param_groups[0][\"lr\"]!= None):\n",
    "    accuracy, average_loss = trainModel(model, criterion, optimizer, train_generator)\n",
    "    scheduler.step()\n",
    "\n",
    "    tabLearningRate+= [optimizer.param_groups[0][\"lr\"]]\n",
    "    tabLoss+=[average_loss]\n",
    "    \n",
    "\n",
    "    print(f'Epoch {epoch} - '\n",
    "          f'Accuracy: {accuracy:.4f} - '\n",
    "          f'Average Loss: {average_loss:.4f} - '\n",
    "          f'Learning Rate: {optimizer.param_groups[0][\"lr\"]:}')\n",
    "    epoch+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d38368a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(tabLearningRate, tabLoss)\n",
    "plt.xlabel('learning rate')\n",
    "plt.xscale('log')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c55040ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best LearningRate: 0.0012589254117941677\n"
     ]
    }
   ],
   "source": [
    "min_y = min(tabLoss)\n",
    "min_index = tabLoss.index(min_y)\n",
    "\n",
    "LearningRate = tabLearningRate[min_index]\n",
    "print('best LearningRate:',LearningRate)\n",
    "#best LearningRate: 0.0008912509381337458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e4e5ce9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Loss: 1.7758 - Accuracy: 0.3812 - Time: 3.35 seconds - Val Loss: 1.4244 - Val Accuracy: 0.5800 - Time: 0.20 seconds\n",
      "Epoch 2/100 - Loss: 1.1864 - Accuracy: 0.6362 - Time: 3.45 seconds - Val Loss: 1.3626 - Val Accuracy: 0.6100 - Time: 0.19 seconds\n",
      "Epoch 3/100 - Loss: 0.9281 - Accuracy: 0.7412 - Time: 3.51 seconds - Val Loss: 1.2638 - Val Accuracy: 0.6700 - Time: 0.20 seconds\n",
      "Epoch 4/100 - Loss: 0.7729 - Accuracy: 0.8075 - Time: 3.57 seconds - Val Loss: 1.1507 - Val Accuracy: 0.6800 - Time: 0.19 seconds\n",
      "Epoch 5/100 - Loss: 0.6011 - Accuracy: 0.8750 - Time: 3.66 seconds - Val Loss: 1.1537 - Val Accuracy: 0.6600 - Time: 0.17 seconds\n",
      "Epoch 6/100 - Loss: 0.5292 - Accuracy: 0.8938 - Time: 3.69 seconds - Val Loss: 1.1518 - Val Accuracy: 0.6900 - Time: 0.19 seconds\n",
      "Epoch 7/100 - Loss: 0.4246 - Accuracy: 0.9237 - Time: 3.53 seconds - Val Loss: 1.1521 - Val Accuracy: 0.7100 - Time: 0.18 seconds\n",
      "Epoch 8/100 - Loss: 0.3837 - Accuracy: 0.9325 - Time: 3.70 seconds - Val Loss: 1.0908 - Val Accuracy: 0.7300 - Time: 0.18 seconds\n",
      "Epoch 9/100 - Loss: 0.3184 - Accuracy: 0.9625 - Time: 3.67 seconds - Val Loss: 1.1314 - Val Accuracy: 0.7000 - Time: 0.19 seconds\n",
      "Epoch 10/100 - Loss: 0.2780 - Accuracy: 0.9613 - Time: 3.66 seconds - Val Loss: 1.0607 - Val Accuracy: 0.7200 - Time: 0.17 seconds\n",
      "Epoch 11/100 - Loss: 0.2405 - Accuracy: 0.9675 - Time: 3.68 seconds - Val Loss: 1.0918 - Val Accuracy: 0.7400 - Time: 0.19 seconds\n",
      "Epoch 12/100 - Loss: 0.2166 - Accuracy: 0.9725 - Time: 3.58 seconds - Val Loss: 1.0292 - Val Accuracy: 0.7500 - Time: 0.19 seconds\n",
      "Epoch 13/100 - Loss: 0.1683 - Accuracy: 0.9812 - Time: 3.69 seconds - Val Loss: 1.1106 - Val Accuracy: 0.7400 - Time: 0.18 seconds\n",
      "Epoch 14/100 - Loss: 0.1718 - Accuracy: 0.9838 - Time: 3.59 seconds - Val Loss: 0.9741 - Val Accuracy: 0.7200 - Time: 0.17 seconds\n",
      "Epoch 15/100 - Loss: 0.1351 - Accuracy: 0.9875 - Time: 3.60 seconds - Val Loss: 1.0082 - Val Accuracy: 0.7400 - Time: 0.19 seconds\n",
      "Epoch 16/100 - Loss: 0.1286 - Accuracy: 0.9875 - Time: 3.57 seconds - Val Loss: 1.0275 - Val Accuracy: 0.7200 - Time: 0.17 seconds\n",
      "Epoch 17/100 - Loss: 0.1146 - Accuracy: 0.9950 - Time: 3.52 seconds - Val Loss: 1.0182 - Val Accuracy: 0.7300 - Time: 0.19 seconds\n",
      "Epoch 18/100 - Loss: 0.1036 - Accuracy: 0.9900 - Time: 3.70 seconds - Val Loss: 1.0658 - Val Accuracy: 0.7400 - Time: 0.19 seconds\n",
      "Epoch 19/100 - Loss: 0.0957 - Accuracy: 0.9900 - Time: 3.54 seconds - Val Loss: 1.0365 - Val Accuracy: 0.7400 - Time: 0.19 seconds\n",
      "Epoch 20/100 - Loss: 0.0902 - Accuracy: 0.9938 - Time: 3.65 seconds - Val Loss: 1.0439 - Val Accuracy: 0.7300 - Time: 0.18 seconds\n",
      "Epoch 21/100 - Loss: 0.0802 - Accuracy: 0.9950 - Time: 3.63 seconds - Val Loss: 1.0125 - Val Accuracy: 0.7300 - Time: 0.18 seconds\n",
      "Epoch 22/100 - Loss: 0.0851 - Accuracy: 0.9938 - Time: 3.57 seconds - Val Loss: 1.0773 - Val Accuracy: 0.7500 - Time: 0.18 seconds\n",
      "Epoch 23/100 - Loss: 0.0794 - Accuracy: 0.9962 - Time: 3.56 seconds - Val Loss: 1.0812 - Val Accuracy: 0.7400 - Time: 0.18 seconds\n",
      "Epoch 24/100 - Loss: 0.0712 - Accuracy: 0.9938 - Time: 3.57 seconds - Val Loss: 1.1067 - Val Accuracy: 0.7400 - Time: 0.19 seconds\n",
      "Epoch 25/100 - Loss: 0.0553 - Accuracy: 0.9988 - Time: 3.59 seconds - Val Loss: 1.0391 - Val Accuracy: 0.7400 - Time: 0.18 seconds\n",
      "Epoch 26/100 - Loss: 0.0696 - Accuracy: 0.9888 - Time: 3.54 seconds - Val Loss: 1.0503 - Val Accuracy: 0.7300 - Time: 0.18 seconds\n",
      "Epoch 27/100 - Loss: 0.0566 - Accuracy: 0.9962 - Time: 3.62 seconds - Val Loss: 1.0899 - Val Accuracy: 0.7400 - Time: 0.17 seconds\n",
      "Epoch 28/100 - Loss: 0.0451 - Accuracy: 0.9962 - Time: 3.60 seconds - Val Loss: 1.0988 - Val Accuracy: 0.7400 - Time: 0.19 seconds\n",
      "Epoch 29/100 - Loss: 0.0419 - Accuracy: 1.0000 - Time: 3.70 seconds - Val Loss: 1.0534 - Val Accuracy: 0.7400 - Time: 0.19 seconds\n",
      "Epoch 30/100 - Loss: 0.0417 - Accuracy: 0.9988 - Time: 3.65 seconds - Val Loss: 1.0606 - Val Accuracy: 0.7400 - Time: 0.18 seconds\n",
      "Epoch 31/100 - Loss: 0.0355 - Accuracy: 1.0000 - Time: 3.54 seconds - Val Loss: 1.0593 - Val Accuracy: 0.7300 - Time: 0.19 seconds\n",
      "Epoch 32/100 - Loss: 0.0422 - Accuracy: 0.9988 - Time: 3.52 seconds - Val Loss: 1.1255 - Val Accuracy: 0.7400 - Time: 0.18 seconds\n",
      "Epoch 33/100 - Loss: 0.0512 - Accuracy: 0.9988 - Time: 3.60 seconds - Val Loss: 1.0983 - Val Accuracy: 0.7500 - Time: 0.18 seconds\n",
      "Epoch 34/100 - Loss: 0.0380 - Accuracy: 1.0000 - Time: 3.43 seconds - Val Loss: 1.0190 - Val Accuracy: 0.7400 - Time: 0.18 seconds\n",
      "Epoch 35/100 - Loss: 0.0337 - Accuracy: 1.0000 - Time: 3.57 seconds - Val Loss: 1.0182 - Val Accuracy: 0.7400 - Time: 0.19 seconds\n",
      "Epoch 36/100 - Loss: 0.0311 - Accuracy: 1.0000 - Time: 3.50 seconds - Val Loss: 1.0661 - Val Accuracy: 0.7400 - Time: 0.18 seconds\n",
      "Epoch 37/100 - Loss: 0.0473 - Accuracy: 0.9938 - Time: 3.46 seconds - Val Loss: 1.0560 - Val Accuracy: 0.7400 - Time: 0.19 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     14\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 15\u001b[0m     accuracy_train, loss_train \u001b[38;5;241m=\u001b[39m trainModel(model, criterion, optimizer, train_generator)\n\u001b[1;32m     16\u001b[0m     epoch_time_train \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Ajouter les m√©triques √† TensorBoard\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[57], line 17\u001b[0m, in \u001b[0;36mtrainModel\u001b[0;34m(model, criterion, optimizer, dataset)\u001b[0m\n\u001b[1;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#print(\"loss\",loss)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#print()\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     20\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "\n",
    "#LearningRate = 0.0008912509381337458\n",
    "num_epochs=30\n",
    "\n",
    "model = SimpleCNN()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LearningRate)\n",
    "\n",
    "writer = SummaryWriter()\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    accuracy_train, loss_train = trainModel(model, criterion, optimizer, train_generator)\n",
    "    epoch_time_train = time.time() - start_time\n",
    "\n",
    "    # Ajouter les m√©triques √† TensorBoard\n",
    "    writer.add_scalar('Loss/train', loss_train, epoch)\n",
    "    writer.add_scalar('Accuracy/train', accuracy_train, epoch)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    accuracy_val,loss_val = ValidatModel(model, criterion, optimizer, validation_generator)\n",
    "    epoch_time_val = time.time() - start_time\n",
    "        \n",
    "    writer.add_scalar('Loss/val', loss_val, epoch)\n",
    "    writer.add_scalar('Accuracy/val', accuracy_val, epoch)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs} - '\n",
    "      f'Loss: {loss_train:.4f} - Accuracy: {accuracy_train:.4f} - '\n",
    "      f'Time: {epoch_time_train:.2f} seconds - '\n",
    "      f'Val Loss: {loss_val:.4f} - Val Accuracy: {accuracy_val:.4f} - '\n",
    "      f'Time: {epoch_time_val:.2f} seconds')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8ce27c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: blues is 70.0 %\n",
      "Accuracy for class: classical is 100.0 %\n",
      "Accuracy for class: country is 70.0 %\n",
      "Accuracy for class: disco is 70.0 %\n",
      "Accuracy for class: hiphop is 60.0 %\n",
      "Accuracy for class: jazz  is 70.0 %\n",
      "Accuracy for class: metal is 100.0 %\n",
      "Accuracy for class: pop   is 90.0 %\n",
      "Accuracy for class: reggae is 50.0 %\n",
      "Accuracy for class: rock  is 60.0 %\n"
     ]
    }
   ],
   "source": [
    "classes = ('blues', 'classical', 'country', 'disco', 'hiphop','jazz','metal','pop','reggae', 'rock')\n",
    "\n",
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in validation_generator:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f43c2db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 100 test images: 61 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in test_generator:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 100 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba6ad52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
