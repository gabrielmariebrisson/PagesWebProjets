import streamlit as st
import tensorflow as tf
import pickle
from tensorflow.keras.preprocessing.sequence import pad_sequences

# D√©finir la configuration de la page en premier
# Au d√©but de votre script
st.set_page_config(
    page_title="Analyse de Sentiments",
    page_icon="üòä",  # Ajoutez une ic√¥ne
    layout="wide",
    initial_sidebar_state="expanded",
)

# Personnaliser le style avec du CSS personnalis√©
st.markdown("""
<style>
    /* Fond g√©n√©ral */
    .reportview-container {
        background-color: #F4F6F9;
        font-family: 'Inter', 'Segoe UI', Roboto, sans-serif;
    }

    /* Titres */
    h1, h2, h3 {
        color: #2C3E50;
        font-weight: 700;
        letter-spacing: -0.5px;
        background: linear-gradient(45deg, #3498db, #2ecc71);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
    }

    /* Am√©lioration des en-t√™tes */
    .css-1h7aky3 {
        background-color: rgba(44, 62, 80, 0.05);
        padding: 15px;
        border-radius: 10px;
        margin-bottom: 20px;
    }

    /* Boutons */
    .stButton>button {
        color: white;
        background-color: #3498db;
        border: none;
        border-radius: 25px;
        padding: 10px 20px;
        font-weight: 600;
        transition: all 0.3s ease;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }

    .stButton>button:hover {
        background-color: #2980b9;
        transform: translateY(-2px);
        box-shadow: 0 6px 8px rgba(0,0,0,0.15);
    }

    
</style>
""", unsafe_allow_html=True)

# Charger le mod√®le
@st.cache_resource
def load_model():
    return tf.keras.models.load_model('./templates/assets/AnalyseSentiment.h5')

model = load_model()

@st.cache_resource
def load_tokenizer():
    with open('./templates/assets/tokenizer.pkl', 'rb') as handle:
        return pickle.load(handle)

tokenizer = load_tokenizer()

# Fonction pour traiter les s√©quences
def seq_pad_and_trunc(sequences, tokenizer, padding='post', truncating='post', maxlen=100):
    sequences = tokenizer.texts_to_sequences([sequences])
    padded_sequences = pad_sequences(sequences, maxlen=maxlen, padding=padding, truncating=truncating)
    return padded_sequences

# Bouton de redirection
st.markdown(
    """
    <a href="https://gabriel.mariebrisson.fr" target="_blank" style="text-decoration:none;">
    <div style="
    display: inline-block;
    background: linear-gradient(135deg, #6A11CB 0%, #2575FC 100%);
    color: white;
    padding: 12px 25px;
    border-radius: 30px;
    text-align: center;
    font-size: 16px;
    font-weight: 600;
    cursor: pointer;
    box-shadow: 0 4px 15px rgba(37, 117, 252, 0.3);
    transition: all 0.3s ease;
    text-transform: uppercase;
    letter-spacing: 1px;
    border: 2px solid transparent;
    position: relative;
    overflow: hidden;
    ">
    Retour
    <span style="
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    background: rgba(255,255,255,0.2);
    transform: scaleX(0);
    transform-origin: right;
    transition: transform 0.3s ease;
    z-index: 1;
    "></span>
    </div>
    </a>
    """,
    unsafe_allow_html=True
)

# Titre et introduction
st.title("Projet NLP : Surajustement et Classification des Sentiments")
st.markdown(
    """
    Ce projet utilise un mod√®le de r√©seau de neurones d√©velopp√© avec TensorFlow/Keras pour analyser 
    les sentiments dans des tweets, en exploitant une architecture bas√©e sur les embeddings GloVe.
    """
)



# Analyse de texte
# Modification de la section d'analyse
st.header("üîç Analyse de Sentiment en Temps R√©el")

col1, col2 = st.columns([3, 1])

with col1:
    user_input = st.text_area(
        "Entrez un texte en anglais pour tester le mod√®le :",
        placeholder="Tapez votre texte ici...",
        height=150
    )

with col2:
    st.write("") # Espace pour aligner
    st.write("") # Espace pour aligner
    analyze_button = st.button("üß† Analyser", type="primary")

if analyze_button:
    if user_input:
        # Votre code de pr√©diction existant
        processed_input = seq_pad_and_trunc(user_input, tokenizer)
        prediction = model.predict(processed_input)
        
        sentiment = "positif" if prediction[0][0] > 0.5 else "n√©gatif"
        
        # Affichage am√©lior√©
        col_result1, col_result2 = st.columns(2)
        
        with col_result1:
            st.metric(
                label="Sentiment", 
                value=sentiment.capitalize(), 
                delta=f"{prediction[0][0]:.2f} de probabilit√© 0 pour negatif 1 pour positif"
            )

        st.balloons()
        
        with col_result2:
            if sentiment == "positif":
                st.success("üåû Sentiment Positif D√©tect√©!")
            else:
                st.warning("üåßÔ∏è Sentiment N√©gatif D√©tect√©.")
    else:
        st.error("Veuillez entrer un texte avant de lancer l'analyse.")




# Section Pr√©sentation
st.header("Pr√©sentation")
st.markdown(
    """
    Ce projet vise √† classifier les tweets en fonction des sentiments exprim√©s par les utilisateurs. Les r√©seaux sociaux jouent un r√¥le pr√©pond√©rant dans la communication moderne, permettant √† chacun d'exprimer librement son opinion. Les applications de cette technologie sont nombreuses :

    **Applications potentielles :**
    - **Marketing :** Analyser la perception d'une marque sur les r√©seaux sociaux.
    - **Service client :** Surveiller en temps r√©el les commentaires des clients.
    - **Pr√©visions de tendances :** Aider les entreprises √† anticiper les besoins des consommateurs.
    - **Ressources humaines :** √âvaluer le moral des employ√©s.
    - **Finance :** Pr√©dire l'√©volution des cours boursiers.

    Pour cela, nous avons utilis√© le jeu de donn√©es Sentiment140, qui contient 1,6 million de tweets √©tiquet√©s par sentiment (0 pour n√©gatif, 4 pour positif). Contrairement √† un d√©ploiement industriel, cette approche ne n√©cessite pas une ing√©nierie des donn√©es compl√®te, incluant l'extraction, le nettoyage et la gestion des donn√©es manquantes. Le code a √©t√© d√©velopp√© lors de la certification TensorFlow, Cours 3, semaine 3, et vous pouvez le retrouver ici : [GitHub](https://github.com).
    """
)

# Section Architecture du Mod√®le
st.header("Architecture du Mod√®le")
st.markdown(
    """
    Pour classifier un texte, il est essentiel de le transformer en un format compr√©hensible par la machine. Nous avons utilis√© la m√©thode d'embedding pr√©entra√Æn√©e GloVe de Stanford. Cette technique tient compte de la fr√©quence √† laquelle des paires de mots apparaissent ensemble dans les textes, permettant ainsi de capturer des relations s√©mantiques subtiles entre les mots. Par exemple, une op√©ration vectorielle possible est : roi - homme + femme ‚âà reine. Une approche plus moderne consisterait √† utiliser une architecture de type transformateur.

    Le mod√®le de classification des sentiments se compose de plusieurs couches :
    - **Couche d'embedding :** Cette couche int√®gre la matrice d'embedding GloVe, permettant d'ajuster les poids pour g√©rer les mots non pr√©sents dans le vocabulaire de GloVe et de r√©duire la taille de la matrice.
    - **Couche Conv1D :** Elle capture les relations temporelles au sein des s√©quences textuelles. Bien que j'aurais pu utiliser des couches bidirectionnelles ou LSTM, qui sont plus adapt√©es, cela aurait prolong√© le temps d'entra√Ænement.
    - **Couche Dense :** Cette couche fournit la sortie finale en agr√©geant les informations contextuelles extraites des couches pr√©c√©dentes.

    Les hyperparam√®tres, tels que le nombre de neurones et le taux d'apprentissage, jouent un r√¥le crucial dans les performances du mod√®le. Parmi ces hyperparam√®tres figurent : le nombre de neurones, le taux d'apprentissage, la longueur maximale des s√©quences et la dimension de l'embedding.
    """
)
st.image("./templates/assets/images/Architecture.png", caption="Structure du mod√®le de classification des sentiments", use_container_width=True)

# Section R√©sultats
st.header("R√©sultats")
st.markdown(
    """
    Les techniques les plus efficaces pour limiter le surajustement incluent la r√©gularisation par dropout et la r√©duction de la complexit√© du mod√®le. Ces approches ont permis d'obtenir des r√©sultats significatifs, comme en t√©moignent les courbes ci-dessous.

    En observant les courbes d'apprentissage, nous notons une convergence stable avec une pr√©cision atteignant 75 % sur les donn√©es de test (r√©partition 90/10) et 79 % sur les donn√©es d'apprentissage. Cela d√©montre une bonne capacit√© du mod√®le √† g√©n√©raliser sans trop s'adapter aux sp√©cificit√©s des donn√©es d'entra√Ænement.
    """
)

col1, col2 = st.columns(2)

with col1:
    st.image("./templates/assets/images/accurancy.png", caption="Courbes de pr√©cision", use_container_width=True)

with col2:
    st.image("./templates/assets/images/loss.png", caption="Courbes de perte", use_container_width=True)

st.markdown(
    """
    **Performances du mod√®le :**
    - Pr√©cision de 75 % sur les donn√©es de test.
    - Pr√©cision de 79 % sur les donn√©es d'apprentissage.
    - Bonne g√©n√©ralisation sans surajustement.

    En plus de la r√©gularisation, des techniques telles que l'augmentation des donn√©es et l'ajustement des hyperparam√®tres ont √©t√© envisag√©es pour am√©liorer davantage les performances du mod√®le. Cela permettrait non seulement d'optimiser la pr√©cision, mais √©galement d'accro√Ætre la robustesse face √† des donn√©es vari√©es.
    """
)

# Section Co√ªt et Maintenance
st.header("Co√ªt de D√©veloppement")
st.markdown(
    """
    Pour entra√Æner ce mod√®le, nous avons utilis√© Google Colab, o√π l'entra√Ænement √† dur√© 13 minutes. Voici les sp√©cifications mat√©rielles utilis√©es :

    - **Processeur :** Intel Xeon (simple c≈ìur) cadenc√© √† 2,2 GHz.
    - **RAM :** 12,67 GiB.

    Les performances obtenues montrent une pr√©cision de 75 % sur les donn√©es de test et de 79 % sur les donn√©es d'apprentissage. Le poids du mod√®le charg√© est de 52 Mo, et le temps d'ex√©cution pour un test est de seulement 0,21 seconde.

    **Analyse des co√ªts :**
    - Le co√ªt d'entra√Ænement est raisonnable gr√¢ce √† l'utilisation de Google Colab, qui offre des ressources GPU gratuites pour des projets de petite √† moyenne envergure.
    - Les co√ªts de maintenance incluront principalement les mises √† jour des donn√©es et l'optimisation des hyperparam√®tres.

    **Perspectives d'am√©lioration :**
    - Tester des architectures plus complexes comme les r√©seaux de neurones r√©currents (RNN) ou les Transformers.
    - Utiliser des techniques d'augmentation de donn√©es pour enrichir l'ensemble d'apprentissage.
    - Impl√©menter une validation crois√©e pour mieux √©valuer la robustesse du mod√®le.
    """
)


# Footer
st.markdown(
    """
    ---
    D√©velopp√© par [Gabriel Marie-Brisson](https://gabriel.mariebrisson.fr)
    """
)
